{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\georg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response from the model:\n",
      "```json\n",
      "{\n",
      "  \"Food\": [\"Bakery\", \"Butcher\", \"Coffee Shop\", \"Fast Food\", \"Grocery Store\", \"Restaurant\"],\n",
      "  \"Health\": [\"Doctor's Visit\", \"Dentist\", \"Pharmacy\", \"Vet Visit\"],\n",
      "  \"Home\": [\"Home Improvement\", \"House Cleaning\", \"Home Insurance\", \"Property Tax\"],\n",
      "  \"Personal Care\": [\"Beauty Salon\", \"Florist\", \"Gift Shop\", \"Hair Salon\", \"Spa\"],\n",
      "  \"Transportation\": [\"Airline Ticket\", \"Car Rental\", \"Courier Service\", \"Gas Station\", \"Parking\", \"Public Transport\", \"Taxi\", \"Uber\"],\n",
      "  \"Entertainment\": [\"Concert Ticket\", \"Movie Theater\", \"Netflix\", \"Online Course\", \"Subscription Box\", \"Streaming Service\"],\n",
      "  \"Shopping\": [\"Amazon\", \"Book Store\", \"Clothing Store\", \"Electronics Store\", \"Furniture Store\", \"Hardware Purchase\", \"Music Instrument Store\"],\n",
      "  \"Services\": [\"Accounting Service\", \"Business Service\", \"Childcare Service\", \"Consulting Fee\", \"Education Fee\", \"Freelance Payment\", \"Gardening Service\", \"Legal Service\", \"Maintenance Fee\"],\n",
      "  \"Investments\": [\"Investment\", \"Mortgage\"],\n",
      "  \"Charity\": [\"Charity Donation\"],\n",
      "  \"Other\": [\"Bank Fee\", \"Lottery Ticket\"]\n",
      "}\n",
      "```\n",
      "Model accuracy: 100.00%\n",
      "Predicted categories for new transactions: ['other' 'other']\n",
      "Updated dataset saved to 'final_categorized_transactions.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import re  # Importing the re module for regular expressions\n",
    "\n",
    "# Step 1: Load the CSV file into a DataFrame\n",
    "file_path = 'Extended_Transaction_Dataset.csv'\n",
    "transactions_df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Configure the Gemini API with your API key\n",
    "api_key = \"AIzaSyDOExmBe0spo7h7PXGRbFqiPRPzfn5FdxE\"  # Replace with your actual API key\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Step 3: Extract unique transaction types\n",
    "unique_transaction_types = transactions_df['Transaction_Type'].unique()\n",
    "\n",
    "# Step 4: Send all unique transaction types in a single prompt with a structured format request\n",
    "bulk_prompt = \"\"\"\n",
    "Categorize the following transaction types and return the results in a JSON format where each category is a key and the transaction types that belong to that category are listed as an array of values. For example:\n",
    "{\n",
    "  \"Transportation\": [\"Uber\", \"Taxi\"],\n",
    "  \"Food\": [\"Restaurant\", \"Grocery Store\"],\n",
    "  ...\n",
    "}\n",
    "do not leave out any transaction type\n",
    "Transaction types:\n",
    "\"\"\"\n",
    "bulk_prompt += \"\\n\".join(unique_transaction_types)\n",
    "\n",
    "response = genai.generate_text(\n",
    "    model=\"models/text-bison-001\",  # Use the appropriate model name\n",
    "    prompt=bulk_prompt\n",
    ")\n",
    "\n",
    "# Step 5: Print the raw response for debugging\n",
    "print(\"Raw response from the model:\")\n",
    "print(response.result)\n",
    "\n",
    "# Step 6: Manual parsing of the response\n",
    "# Remove any problematic characters that might interfere with JSON parsing\n",
    "raw_response = response.result.strip()\n",
    "\n",
    "# Use regex to find all the category names and their associated transaction types\n",
    "category_mapping = {}\n",
    "category_pattern = r'\\\"(.*?)\\\":\\s*\\[(.*?)\\]'\n",
    "matches = re.findall(category_pattern, raw_response, re.DOTALL)\n",
    "\n",
    "for match in matches:\n",
    "    category = match[0]\n",
    "    transactions = re.findall(r'\\\"(.*?)\\\"', match[1])\n",
    "    category_mapping[category] = transactions\n",
    "\n",
    "# Step 7: Create a reverse mapping from transaction type to category\n",
    "transaction_to_category = {}\n",
    "for category, transactions in category_mapping.items():\n",
    "    for transaction in transactions:\n",
    "        transaction_to_category[transaction] = category\n",
    "\n",
    "# Step 8: Assign categories to the dataset\n",
    "transactions_df['Gemini_Category'] = transactions_df['Transaction_Type'].map(transaction_to_category)\n",
    "\n",
    "# Step 9: Handle NaN values (replace with \"other\" if any)\n",
    "transactions_df['Gemini_Category'].fillna('other', inplace=True)\n",
    "\n",
    "# Step 10: Train a machine learning model on the categorized data\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    transactions_df['Transaction_Type'], transactions_df['Gemini_Category'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Step 11: Predict categories for new transaction types\n",
    "new_transaction_types = [\"New Transaction 1\", \"New Transaction 2\"]\n",
    "predicted_categories = model.predict(new_transaction_types)\n",
    "print(\"Predicted categories for new transactions:\", predicted_categories)\n",
    "\n",
    "# Step 12: Save the updated DataFrame with categories\n",
    "output_file_path = 'final_categorized_transactions.csv'\n",
    "transactions_df.to_csv(output_file_path, index=False)\n",
    "print(f\"Updated dataset saved to '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
